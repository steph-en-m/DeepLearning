{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot the Mask Challenge:\n",
    "\n",
    "Can you predict whether a person in an image is wearing a face mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import utils # My Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data:\n",
    "> Phase1:\n",
    "* Load the images into the workspace\n",
    "* Split the images into train and test images\n",
    "* Create train and test image directories\n",
    "* Move images to the train and test directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "image_dir = \"./images/\"\n",
    "train_dir = \"./raw/train_labels.csv\"\n",
    "sub_dir = \"./raw/sample_sub.csv\"\n",
    "\n",
    "sub = pd.read_csv(sub_dir)\n",
    "train_data = pd.read_csv(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating train and test directories to store the respective images:\n",
    "Note: These methods are to be run once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the create_dir method in utils.py ^_^\n",
    "dirs = ['train', 'test']\n",
    "utils.create_dir(dirs, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test images\n",
    "img_names = os.listdir(image_dir)\n",
    "train_img_names = train_data.image.tolist()\n",
    "test_img_names = []\n",
    "\n",
    "for img in img_names:\n",
    "    if img not in train_img_names:\n",
    "        test_img_names.append(img)\n",
    "\n",
    "# Move train images to the train dir\n",
    "utils.move_images(train_img_names, image_dir, './images/train')\n",
    "\n",
    "# Move test images to the test dir\n",
    "utils.move_images(test_img_names, image_dir, './images/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data:\n",
    "> Phase2:\n",
    "* Analyse the spread of images between the classes to check whether the dataset is balanced or not.\n",
    "* Split the train images further into train and validation images.\n",
    "* Create train and validation image generators.\n",
    " * I'll be using tensorflow's (keras) `ImageDataGenerator()` to load the images. The Dataset API `(tf.data.Dataset())` provides another way of loading data with tensorflow.\n",
    " * Image transformation such as normalizing pixel values and augmentations such as horizontal flipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the image class distributions in the train set\n",
    "train_data['target'].value_counts().plot.bar()\n",
    "plt.title('Image class distributions')\n",
    "plt.xlabel('Classes (0: No mask) (1: Mask)')\n",
    "plt.ylabel('Number of images in train set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the image generator with `class_mode=\"categorical\"`, the `target` column needs to be a string: The image generator will then one-hot encode it.\n",
    "So I'll create a mapping `{0: 'No_mask', 1: 'Mask'}` of the target classes from integer to string ; given that there are only two classes represented in the dataset.i.e images with masks (or with people wearing masks) and those without masks in them.\n",
    "\n",
    "And finally split the train set into a train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further splitting the train images into train and validation images.\n",
    "train_data['target'] = train_data['target'].replace({0: 'No_mask', 1: 'Mask'})\n",
    "\n",
    "tr_data, val_data = train_test_split(train_data, test_size=0.20, random_state=42)\n",
    "tr_data = tr_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-check the the image class distributions\n",
    "tr_data['target'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = tr_data.shape[0]  #total train images\n",
    "total_validate = val_data.shape[0] #total images on validation set\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    tr_data, \n",
    "    './images/train/train/', \n",
    "    x_col = 'image',\n",
    "    y_col = 'target',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    val_data, \n",
    "    './images/train/train/', \n",
    "    x_col='image',\n",
    "    y_col='target',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(0, 8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    for X_batch, Y_batch in train_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training:\n",
    "Approach-1 (Build ConvNet from scratch)\n",
    "\n",
    "Task-bag:\n",
    "* Define the Model and its attributes `(Model Architecture)`\n",
    "    * I'll make use of the `Sequential()` api defined in `tf.keras.models`\n",
    "* Compile the model\n",
    "    * Since there are 2 classes of images in the dataset, I'll set `loss=binary_crossentropy`.\n",
    "* Define training parameters and optimizations\n",
    "    * EarlyStopping\n",
    "    * learning rate decay.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "model = Sequential()\n",
    "#Layer1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Layer2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Layer3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Classification layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(2, activation='softmax')) # 2 because there are 2 classes\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience=5) # Stop if validation loss doesn't improve after 5 epochs\n",
    "\n",
    "# Gradually reduce the learning rate if validation loss doesn't improve after 5 steps\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001\n",
    "                                           )\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "epochs = 10 if FAST_RUN else 100 #200\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 70, #total_validate//batch_size,\n",
    "    steps_per_epoch = 70, #total_train//batch_size,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, epochs, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, epochs, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning (Approach-2):\n",
    "Given that the dataset is small `~1300 train images`, its image size is insufficient to train a model that can generalize well on unseen data.\n",
    "\n",
    "**Transfer learning** is a technique of model training that relies on a pretrained model (model already trained on a larger dataset) to train a new one in the same domain area (Computer Vision, NLP or RL).\n",
    "\n",
    "*Modes of training with transfer learning:*\n",
    "* Feature extraction:\n",
    "\n",
    "     * One way of doing transfer learning is by instantiating a pre-trained model without the classification/top layer, adding a custom fully-connected layer i.e a `Dense()` layer on top and `freezing` the pretrained model so that only the weights of the new model get updated during training.\n",
    "     \n",
    "    With this method, the convolutional base of the pretrained model acts as a `feature extractor`; extracting all features associated with each image and the `Dense()` layer (top layer) determines the image class from the set of features.\n",
    " \n",
    "* Fine tuning:\n",
    "    * Here the pretrained model is trained further (usually from a specific layer to the top/end) to improve performance.\n",
    "   \n",
    "More about transfer learning: [Here](https://www.tensorflow.org/tutorials/images/transfer_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MobileNet-V2 pre-trained model\n",
    "# I'll be using it as a feature extractor here\n",
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing Model Weights (convolutional base)\n",
    "#Freezing (by setting layer.trainable = False) prevents the weights of the pretrained model from being updated during training.\n",
    "mobile_net.trainable = False\n",
    "\n",
    "# Visualizing base model architecture\n",
    "mobile_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model for training\n",
    "mobileNet_model = Sequential([\n",
    "    mobile_net,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "mobileNet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 if FAST_RUN else 200\n",
    "hist = mobileNet_model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 60,\n",
    "    steps_per_epoch = 60,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "mobileNet_model.save_weights(\"mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir('./images/test/test/')\n",
    "test_df = pd.DataFrame({\n",
    "    'image': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    './images/test/test/', \n",
    "    x_col='image',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
    "predictions = mobileNet_model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical classication the prediction is the probability of each class being present in an image, so we will pick the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = predictions.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['target'] = predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test_df.copy()\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('./submissions')\n",
    "sub.to_csv('./submissions/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* A better score using both approaches can be attained.\n",
    "    * Approach-1: \n",
    "        * Do more data augmentation\n",
    "        * Change model architecture.e.g. add more convolutional layers\n",
    "        * Tweaking other optimization params; learning_rate, batch_size, etc\n",
    "    * Approach-2:\n",
    "        * Data augmentation also applies here.\n",
    "        * Use other Hyper-params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

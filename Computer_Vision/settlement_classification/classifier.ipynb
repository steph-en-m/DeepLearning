{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANSA AWS Informal Settlements in South Africa:\n",
    "\n",
    "Use high resolution satellite imagery from urban South Africa to identify the locations of informal settlements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "image_dir = \"./images/\"\n",
    "train_dir = \"./Train.csv\"\n",
    "sub_dir = \"./SampleSubmission.csv\"\n",
    "\n",
    "sub = pd.read_csv(sub_dir)\n",
    "train_data = pd.read_csv(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH = 512\n",
    "IMAGE_HEIGHT = 512\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = os.listdir('./images/train/train_images/')\n",
    "image_df = pd.DataFrame({\n",
    "    'ID': [train_filenames[i].strip('.jpg') for i,_ in enumerate(train_filenames)],\n",
    "    'image': train_filenames\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.merge(image_df, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>Label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059CI9</td>\n",
       "      <td>-25.723</td>\n",
       "      <td>28.392</td>\n",
       "      <td>False</td>\n",
       "      <td>0059CI9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007HEF7</td>\n",
       "      <td>-25.691</td>\n",
       "      <td>28.448</td>\n",
       "      <td>False</td>\n",
       "      <td>007HEF7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00IKFRY</td>\n",
       "      <td>-25.733</td>\n",
       "      <td>28.421</td>\n",
       "      <td>True</td>\n",
       "      <td>00IKFRY.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01FS05D</td>\n",
       "      <td>-25.771</td>\n",
       "      <td>28.379</td>\n",
       "      <td>False</td>\n",
       "      <td>01FS05D.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01QE5P2</td>\n",
       "      <td>-25.749</td>\n",
       "      <td>28.413</td>\n",
       "      <td>False</td>\n",
       "      <td>01QE5P2.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID     LAT     LON  Label        image\n",
       "0  0059CI9 -25.723  28.392  False  0059CI9.jpg\n",
       "1  007HEF7 -25.691  28.448  False  007HEF7.jpg\n",
       "2  00IKFRY -25.733  28.421   True  00IKFRY.jpg\n",
       "3  01FS05D -25.771  28.379  False  01FS05D.jpg\n",
       "4  01QE5P2 -25.749  28.413  False  01QE5P2.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00MZGKU</td>\n",
       "      <td>-29.8920</td>\n",
       "      <td>30.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>015JA41</td>\n",
       "      <td>-29.8905</td>\n",
       "      <td>30.8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01POB64</td>\n",
       "      <td>-29.9615</td>\n",
       "      <td>30.8950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      LAT      LON\n",
       "0  00MZGKU -29.8920  30.8575\n",
       "1  015JA41 -29.8905  30.8705\n",
       "2  01POB64 -29.9615  30.8950"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('./Test.csv')\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data:\n",
    "\n",
    "* Analyse the spread of images between the classes to check whether the dataset is balanced or not.\n",
    "* Split the train images further into train and validation images.\n",
    "* Create train and validation image generators.\n",
    " * I'll be using tensorflow's (keras) `ImageDataGenerator()` to load the images. The Dataset API `(tf.data.Dataset())` provides another way of loading data with tensorflow.\n",
    " * Image transformation such as normalizing pixel values and augmentations such as horizontal flipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of images in train set')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the image class distributions in the train set\n",
    "train_data['Label'].value_counts().plot.bar()\n",
    "plt.title('Image class distributions')\n",
    "plt.xlabel('Classes (0: False) (1: True)')\n",
    "plt.ylabel('Number of images in train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further splitting the train images into train and validation images.\n",
    "#train_data['Label'] = train_data['Label'].replace({0:'False', 1:'True'})\n",
    "train_data['Label'] = train_data['Label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "model = Sequential()\n",
    "#Layer1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Layer2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Layer3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Classification layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.2e-3), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Loading the MobileNet-V2 pre-trained model\n",
    "# I'll be using it as a feature extractor here\n",
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "resnet50 = tf.keras.applications.ResNet50(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
    "                                          include_top=False,\n",
    "                                          weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 201, 201, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 100, 100, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 100, 100, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 100, 100, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 100, 100, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 100, 100, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 100, 100, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 100, 100, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 100, 100, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 100, 100, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 100, 100, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 100, 100, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 101, 101, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 50, 50, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 50, 50, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 50, 50, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 50, 50, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 50, 50, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 50, 50, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 50, 50, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 50, 50, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 50, 50, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 50, 50, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 50, 50, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 50, 50, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 50, 50, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 50, 50, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 50, 50, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 50, 50, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 50, 50, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 51, 51, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 25, 25, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 25, 25, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 25, 25, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 25, 25, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 25, 25, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 25, 25, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 25, 25, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 25, 25, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 25, 25, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 25, 25, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 25, 25, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 25, 25, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 25, 25, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 25, 25, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 25, 25, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 25, 25, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 25, 25, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 25, 25, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 25, 25, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 25, 25, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 25, 25, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 25, 25, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 25, 25, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 25, 25, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 25, 25, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 25, 25, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 27, 27, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 13, 13, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 13, 13, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 13, 13, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 13, 13, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 13, 13, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 13, 13, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 13, 13, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 13, 13, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 13, 13, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 13, 13, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 13, 13, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 13, 13, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 13, 13, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 13, 13, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 13, 13, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 13, 13, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 13, 13, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 13, 13, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 13, 13, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 13, 13, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 13, 13, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 13, 13, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 13, 13, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 13, 13, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 13, 13, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 13, 13, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 13, 13, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 13, 13, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 13, 13, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 13, 13, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 13, 13, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 13, 13, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 13, 13, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 13, 13, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 13, 13, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 13, 13, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 13, 13, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 13, 13, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 13, 13, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 13, 13, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 13, 13, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 13, 13, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 13, 13, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 13, 13, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 13, 13, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 13, 13, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 13, 13, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 13, 13, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 13, 13, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 13, 13, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 13, 13, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 13, 13, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 13, 13, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 13, 13, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 13, 13, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 13, 13, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 13, 13, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 13, 13, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 13, 13, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 13, 13, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 13, 13, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Freezing Model Weights (convolutional base)\n",
    "#Freezing (by setting layer.trainable = False) prevents the weights of the pretrained model from being updated during training.\n",
    "mobile_net.trainable = False\n",
    "resnet50.trainable = False\n",
    "# Visualizing base model architecture\n",
    "mobile_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning\n",
    "\n",
    "#MobileNet\n",
    "mobileNet_model = Sequential([\n",
    "    mobile_net,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "mobileNet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#ResNet\n",
    "# Defining the model for training\n",
    "resnet_model = Sequential([\n",
    "    resnet50,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b3 (Model)      (None, 16, 16, 1536)      10783528  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1537      \n",
      "=================================================================\n",
      "Total params: 10,785,065\n",
      "Trainable params: 10,697,769\n",
      "Non-trainable params: 87,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Efficient-Net\n",
    "e_net = tf.keras.Sequential([\n",
    "            efn.EfficientNetB3(\n",
    "            input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        ),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "        \n",
    "e_net.compile(optimizer='adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "    \n",
    "    \n",
    "e_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(patience=3) # Stop if validation loss doesn't improve after 5 epochs\n",
    "\n",
    "# Gradually reduce the learning rate if validation loss doesn't improve after 5 steps\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='lr', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.25, \n",
    "                                            min_lr=0.00001\n",
    "                                           )\n",
    "\n",
    "callbacks = [learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3424 validated image filenames belonging to 2 classes.\n",
      "Found 857 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 11 steps, validate for 11 steps\n",
      "Epoch 1/8\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.7286 - accuracy: 0.5000 - val_loss: 0.8464 - val_accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "11/11 [==============================] - 18s 2s/step - loss: 0.7167 - accuracy: 0.5000 - val_loss: 0.7820 - val_accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "11/11 [==============================] - 18s 2s/step - loss: 0.6989 - accuracy: 0.5000 - val_loss: 0.7582 - val_accuracy: 0.5000\n",
      "Epoch 4/8\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 0.6956 - accuracy: 0.5000\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6955 - accuracy: 0.5000 - val_loss: 0.7233 - val_accuracy: 0.5000\n",
      "Epoch 5/8\n",
      "11/11 [==============================] - 18s 2s/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.7105 - val_accuracy: 0.5000\n",
      "Epoch 6/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.7020 - val_accuracy: 0.5000\n",
      "Epoch 7/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6984 - val_accuracy: 0.5000\n",
      "Epoch 8/8\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 0.6935 - accuracy: 0.5000\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6966 - val_accuracy: 0.5000\n",
      "Found 3425 validated image filenames belonging to 2 classes.\n",
      "Found 856 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 11 steps, validate for 11 steps\n",
      "Epoch 1/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 4/8\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 0.6935 - accuracy: 0.5000\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 5/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 6/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 7/8\n",
      "10/11 [==========================>...] - ETA: 1s - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 8/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Found 3425 validated image filenames belonging to 2 classes.\n",
      "Found 856 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 11 steps, validate for 11 steps\n",
      "Epoch 1/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 4/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 5/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 6/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 7/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 8/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Found 3425 validated image filenames belonging to 2 classes.\n",
      "Found 856 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 11 steps, validate for 11 steps\n",
      "Epoch 1/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 4/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 5/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 6/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 7/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 8/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Found 3425 validated image filenames belonging to 2 classes.\n",
      "Found 856 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 11 steps, validate for 11 steps\n",
      "Epoch 1/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 4/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 5/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 6/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 7/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 8/8\n",
      "11/11 [==============================] - 19s 2s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "splits = 5\n",
    "kfold = StratifiedKFold(n_splits=splits, shuffle=False)\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(train_data, train_data['Label'])):\n",
    "    tr_data = train_data.loc[train_index]\n",
    "    val_data = train_data.loc[val_index]\n",
    "    \n",
    "    tr_data = tr_data.reset_index(drop=True)\n",
    "    val_data = val_data.reset_index(drop=True)\n",
    "    \n",
    "    total_train = tr_data.shape[0]  #total train images\n",
    "    total_validate = val_data.shape[0] #total images on validation set\n",
    "    batch_size = 8\n",
    "    \n",
    "    # Train generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        tr_data, \n",
    "        './images/train/train_images/', \n",
    "        x_col = 'image',\n",
    "        y_col = 'Label',\n",
    "        target_size = IMAGE_SIZE,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "\n",
    "    # Validation generator\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_generator = validation_datagen.flow_from_dataframe(\n",
    "        val_data, \n",
    "        './images/train/train_images/', \n",
    "        x_col='image',\n",
    "        y_col='Label',\n",
    "        target_size=IMAGE_SIZE,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    # Model training\n",
    "    epochs = 3 if FAST_RUN else 8\n",
    "    \n",
    "    hist = e_net.fit(\n",
    "        train_generator, \n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = int(90/batch_size),\n",
    "        steps_per_epoch = int(90/batch_size),\n",
    "        callbacks = callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "resnet_model.save_weights(\"resnet50.h5\")\n",
    "#model.save_weights(\"ConvNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2613"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames = os.listdir('./images/test/test_images/')\n",
    "test_df = pd.DataFrame({\n",
    "    'ID': [test_filenames[i].strip('.jpg') for i,_ in enumerate(test_filenames)],\n",
    "    'image': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2613 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    './images/test/test_images/', \n",
    "    x_col='image',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predictions = e_net.predict(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00MZGKU</td>\n",
       "      <td>0.491683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>015JA41</td>\n",
       "      <td>0.485741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01POB64</td>\n",
       "      <td>0.489499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02125F8</td>\n",
       "      <td>0.480872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03E8VFF</td>\n",
       "      <td>0.493145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID     Label\n",
       "0  00MZGKU  0.491683\n",
       "1  015JA41  0.485741\n",
       "2  01POB64  0.489499\n",
       "3  02125F8  0.480872\n",
       "4  03E8VFF  0.493145"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Label'] = predictions#.max(1)\n",
    "sub = test_df.copy().drop('image', axis=1)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('./submissions')\n",
    "sub.to_csv('./submissions/sub_e-net.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4662356972694397"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sub['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training:\n",
    "Approach-1 (Build ConvNet from scratch)\n",
    "\n",
    "Task-bag:\n",
    "* Define the Model and its attributes `(Model Architecture)`\n",
    "    * I'll make use of the `Sequential()` api defined in `tf.keras.models`\n",
    "* Compile the model\n",
    "    * Since there are 2 classes of images in the dataset, I'll set `loss=binary_crossentropy`.\n",
    "* Define training parameters and optimizations\n",
    "    * EarlyStopping\n",
    "    * learning rate decay.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52/70 [=====================>........] - ETA: 53s - loss: 1.2875 - accuracy: 0.5769"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "epochs = 10 if FAST_RUN else 20 #200\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 70, #total_validate//batch_size,\n",
    "    steps_per_epoch = 70, #total_train//batch_size,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, epochs, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, epochs, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "70/70 [==============================] - 183s 3s/step - loss: 0.6387 - accuracy: 0.6580 - val_loss: 0.6429 - val_accuracy: 0.6911\n",
      "Epoch 2/15\n",
      "70/70 [==============================] - 151s 2s/step - loss: 0.5506 - accuracy: 0.7437 - val_loss: 0.6115 - val_accuracy: 0.7071\n",
      "Epoch 3/15\n",
      "70/70 [==============================] - 140s 2s/step - loss: 0.4695 - accuracy: 0.7911 - val_loss: 0.6022 - val_accuracy: 0.7188\n",
      "Epoch 4/15\n",
      "70/70 [==============================] - 144s 2s/step - loss: 0.4856 - accuracy: 0.7723 - val_loss: 0.5659 - val_accuracy: 0.7214\n",
      "Epoch 5/15\n",
      "70/70 [==============================] - 142s 2s/step - loss: 0.4693 - accuracy: 0.7732 - val_loss: 0.5431 - val_accuracy: 0.7330\n",
      "Epoch 6/15\n",
      "70/70 [==============================] - 138s 2s/step - loss: 0.4626 - accuracy: 0.7866 - val_loss: 0.5275 - val_accuracy: 0.7411\n",
      "Epoch 7/15\n",
      "70/70 [==============================] - 139s 2s/step - loss: 0.4433 - accuracy: 0.7893 - val_loss: 0.5071 - val_accuracy: 0.7527\n",
      "Epoch 8/15\n",
      "70/70 [==============================] - 140s 2s/step - loss: 0.4460 - accuracy: 0.8054 - val_loss: 0.4969 - val_accuracy: 0.7661\n",
      "Epoch 9/15\n",
      "70/70 [==============================] - 148s 2s/step - loss: 0.3860 - accuracy: 0.8241 - val_loss: 0.4941 - val_accuracy: 0.7598\n",
      "Epoch 10/15\n",
      "70/70 [==============================] - 146s 2s/step - loss: 0.3944 - accuracy: 0.8268 - val_loss: 0.4729 - val_accuracy: 0.7705\n",
      "Epoch 11/15\n",
      "70/70 [==============================] - 162s 2s/step - loss: 0.3681 - accuracy: 0.8411 - val_loss: 0.4668 - val_accuracy: 0.7705\n",
      "Epoch 12/15\n",
      "70/70 [==============================] - 176s 3s/step - loss: 0.3772 - accuracy: 0.8438 - val_loss: 0.4551 - val_accuracy: 0.7714\n",
      "Epoch 13/15\n",
      "70/70 [==============================] - 137s 2s/step - loss: 0.3834 - accuracy: 0.8339 - val_loss: 0.4497 - val_accuracy: 0.7777\n",
      "Epoch 14/15\n",
      "70/70 [==============================] - 138s 2s/step - loss: 0.3861 - accuracy: 0.8330 - val_loss: 0.4446 - val_accuracy: 0.7795\n",
      "Epoch 15/15\n",
      "70/70 [==============================] - 137s 2s/step - loss: 0.3342 - accuracy: 0.8571 - val_loss: 0.4370 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 if FAST_RUN else 15\n",
    "hist = mobileNet_model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 70,\n",
    "    steps_per_epoch = 70,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "mobileNet_model.save_weights(\"mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
